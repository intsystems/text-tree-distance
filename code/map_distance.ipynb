{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc7dad8-f70a-4e2f-9632-5bfeed842777",
   "metadata": {},
   "source": [
    "# A BERT-based algorithm for edit distance between text trees\n",
    "\n",
    "This notebook contains the implementation of a simple yet informative metric for text tree comparison. This way of text tree similarity measurement can be used, for example, to compare salient sentence-based mind maps generated by a neural network with reference maps. The way this algorithm works is by applying the Zhang-Shasha algorithm for tree edit distance to text trees, using semantic similarity as the cost of node updates. To measure semantic similarity of sentences in tree nodes, we use a BERT-like language model's embeddings of the sentences, given the context of all parent nodes if available, and compare these embeddings directly.\n",
    "\n",
    "The Zhang-Shasha algorithm implementation is taken from the `zss` Python library developed by Tim Henderson and Steve Johnson (2013). _[here goes the description of what model we use and how we compare embeddings from it]_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4243aa5-af88-4611-b528-5f891595f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zss\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be46c9-c8f8-44c1-b54e-af6f50e02725",
   "metadata": {},
   "source": [
    "First, we will slightly extend the `Node` class from `zss` to include depth information in tree nodes. This will later be useful for similarity weight adjustment for nodes of different depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9861b3b5-885b-49e7-a8fe-6bcedf9c90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(zss.Node):\n",
    "    def __init__(self, label, children=None, depth=0):\n",
    "        '''\n",
    "        Updated version of Node constructor containing self.depth initialization.\n",
    "        '''\n",
    "        self.label = label\n",
    "        self.children = children or list()\n",
    "        self.depth = depth\n",
    "\n",
    "    @staticmethod\n",
    "    def get_depth(node):\n",
    "        '''\n",
    "        Method that returns the node's depth field.\n",
    "        '''\n",
    "        return node.depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779bcf90-3078-40b1-b148-8166e7f44de8",
   "metadata": {},
   "source": [
    "Here we provide a useful function to construct a `similarity_func` for our algorithm from a language model's encoder method and a given similarity function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d55347-0b46-4044-8744-eeecea888313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(encoder, embedding_dist):\n",
    "    '''\n",
    "    A function that constructs the sentence similarity function used in Zhang-Shasha's algorithm.\n",
    "    It uses a language model's encoder and a similarity function to estimate semantic similarity\n",
    "    \n",
    "    Arguments:\n",
    "    encoder - a language model's callable encoder that takes string input returns embeddings from the model\n",
    "    embedding_dist - an embedding similarity measure that takes two embeddings as input and returns a non-negative distance value. \n",
    "\n",
    "    Returns:\n",
    "    similarity_func - function of two string arguments that calculates the between two sentences using the given embedder and distance measure.\n",
    "    '''\n",
    "    def similarity_func(sentence_a, sentence_b):\n",
    "        a_embedding = encoder(sentence_a)\n",
    "        b_embedding = encoder(sentence_b)\n",
    "\n",
    "        return embedding_dist(a_embedding, b_embedding)\n",
    "\n",
    "    return similarity_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c601e95-79d3-49fc-8ce6-a66e195bed32",
   "metadata": {},
   "source": [
    "Also we will need a function to relabel text trees so that each node contains all of the parent nodes' labels a context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fddfc61-69ef-46c9-9614-bf8cac3dc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_with_context(input_node: Node):\n",
    "    '''\n",
    "    A function that creates a relabeled tree based on the input one by adding sentences from parent nodes as context to child nodes.\n",
    "\n",
    "    Arguments:\n",
    "    input_node - root node of the tree to be relabeled.\n",
    "\n",
    "    Returns: root node of relabeled tree.\n",
    "    '''\n",
    "    def add_context(node: Node, context):\n",
    "        new_node = Node(context + Node.get_label(node), depth=Node.get_depth(node))\n",
    "        \n",
    "        for child_node in Node.get_children(node):\n",
    "            new_node.addkid(add_context(child_node, Node.get_label(new_node)))\n",
    "        \n",
    "        return new_node\n",
    "\n",
    "    return add_context(input_node, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73cc59e-1796-4836-a2a4-8ef96f329c21",
   "metadata": {},
   "source": [
    "Finally, we use all the functions above to compute tree distance with `zss.distance`. Note the possible usage of a depth factor to adjust update costs according to the updated node's depth. Our approach can be modified to factor in node depth in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b69e0de0-b7b5-4ee0-8c48-fb0ec752e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tree_distance(tree_a: Node, tree_b: Node, similarity_func, depth_factor=1.0, use_context=True):\n",
    "    '''\n",
    "    The function that calculates tree edit distance between to trees given a similarity function for sentence pairs.\n",
    "    \n",
    "    Arguments:\n",
    "    tree_a, tree_b - two trees of the zss type Node to be compared;\n",
    "    similarity_func - a function of two string arguments which computes sentence distance;\n",
    "    depth_factor - a hyperparameter that scales sentence similarity based on the node's depth;\n",
    "    use_context - a flag indicating whether parents of the given node will be used as context for sentence comparison.\n",
    "    '''\n",
    "    if use_context:\n",
    "        tree_a = tree_with_context(tree_a)\n",
    "        tree_b = tree_with_context(tree_b)\n",
    "\n",
    "    # Here we define the update_cost, insert_cost and delete_cost functions needed for Zhang-Shasha's algorithm using the provided similarity function.\n",
    "    def update_cost(node_a: Node, node_b: Node):\n",
    "        return similarity_func(Node.get_label(node_a), Node.get_label(node_b)) * depth_factor**Node.get_depth(node_a)\n",
    "\n",
    "    def insert_cost(node: Node):\n",
    "        # We define node insertion and deletion costs as similarity of the node's label to an empty string\n",
    "        return similarity_func(Node.get_label(node), \"\")\n",
    "\n",
    "    def remove_cost(node: Node):\n",
    "        return similarity_func(Node.get_label(node), \"\")\n",
    "\n",
    "    dist = zss.distance(tree_a, tree_b, Node.get_children, insert_cost, remove_cost, update_cost)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57bcaf9-f6e8-4cbd-b58a-b017cda31fe4",
   "metadata": {},
   "source": [
    "Below we provide an example use case of the functions above utilizing a model from `sentence_transformers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "381a7a28-d3a0-486b-a150-960b6cc7c545",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v1')\n",
    "\n",
    "def cos_dist(a_embedding, b_embedding):\n",
    "    return float(1 - model.similarity(a_embedding, b_embedding))\n",
    "\n",
    "similarity_func = sentence_similarity(model.encode, cos_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb018879-8685-4c82-9ecb-fb9fb3869dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = (\n",
    "    Node('We present a new metric for text tree comparison.', depth=0)\n",
    "        .addkid(Node('It uses Zhang-Shasha\\'s algorithm and a BERT-like model.', depth=1)\n",
    "            .addkid(Node('Zhang-Shasha\\'s algorithm is used to measure tree edit distance effectively.', depth=2))\n",
    "            .addkid(Node('The BERT-like model is used to measure semantic similarity.', depth=2)))\n",
    "        .addkid(Node('The algorithm is presented as an informative metric for text tree comparison.', depth=1)\n",
    "            .addkid(Node('There hasn\\'t yet been a metric that allows to compare tree-structured text data such as mind maps informatively.', depth=2))\n",
    "            .addkid(Node('This metric can be used, for example, to evaluate automatic salient sentence-based mind map generation.', depth=2)))\n",
    ")\n",
    "\n",
    "B = (\n",
    "    Node('A new metric for text tree comparison based on tree edit distance and semantic similarity.', depth=0)\n",
    "        .addkid(Node('Zhang-Shasha\\'s algorithm is used to compute tree edit distance.', depth=1))\n",
    "        .addkid(Node('Semantic similarity is measured using a BERT-like language model.', depth=1)\n",
    "            .addkid(Node('To measure it, the sentences with all parent nodes as context are passed to the language model.', depth=2))\n",
    "            .addkid(Node('Semantic similarity is measured as the similarity of the model\\'s embeddings of the sentences.', depth=2)))\n",
    "        .addkid(Node('This metric can be used to compare text trees.', depth=1)\n",
    "            .addkid(Node('For example, it can be utilized in automatic mind map generation evaluation against reference maps.', depth=2)))\n",
    ")\n",
    "\n",
    "C = (\n",
    "    Node('A new algorithm for text tree edit distance based on Zhang-Shasha\\'s algorithm and BERT-like model embedding similarity.', depth=0)\n",
    "        .addkid(Node('The algorithm\\'s novelty is in its similarity measure based on BERT-like model embeddings.', depth=1)\n",
    "            .addkid(Node('Embedding distance is used as a measure of semantic similarity.', depth=2))\n",
    "            .addkid(Node('The language model allows to capture semantic meaning of sentences and model their similarity.', depth=2)))\n",
    "        .addkid(Node('Zhang-Shasha\\'s algorithm is used to compute tree edit distance with new edit costs.', depth=1)\n",
    "            .addkid(Node('Semantic similarity is used as the update cost in the algorithm.', depth=2))\n",
    "            .addkid(Node('The costs of insertion and removal of nodes are defined as the similarity of the node and an empty sentence.', depth=2)))\n",
    "        .addkid(Node('The proposed algorithm is presented as a more informative metric of similarity between text trees', depth=1)\n",
    "            .addkid(Node('The current ways of comparing text trees overlook overlook their tree structure or the meaning of their labels.', depth=2))\n",
    "            .addkid(Node('This new method can be used, for example, to compare mind maps or hierarchical summaries.', depth=2)))\n",
    ")\n",
    "\n",
    "A_B_dist = text_tree_distance(A, B, similarity_func)\n",
    "A_C_dist = text_tree_distance(A, C, similarity_func)\n",
    "C_B_dist = text_tree_distance(C, B, similarity_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18b9c890-2132-4358-bf24-75a32c1cec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2734222412109375\n",
      "4.964913785457611\n",
      "5.261121928691864\n"
     ]
    }
   ],
   "source": [
    "print(A_B_dist)\n",
    "print(A_C_dist)\n",
    "print(C_B_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7a58a8e-c76d-4a26-aa2b-be5f75688999",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_B_dist_0_7 = text_tree_distance(A, B, similarity_func, depth_factor=0.7)\n",
    "A_B_dist_1_5 = text_tree_distance(A, B, similarity_func, depth_factor=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79a7fa99-39b9-4aad-8396-1ed542a7fb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.860270586013794\n",
      "4.1851606369018555\n"
     ]
    }
   ],
   "source": [
    "print(A_B_dist_0_7)\n",
    "print(A_B_dist_1_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
