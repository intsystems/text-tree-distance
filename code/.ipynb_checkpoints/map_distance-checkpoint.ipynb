{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc7dad8-f70a-4e2f-9632-5bfeed842777",
   "metadata": {},
   "source": [
    "# A BERT-based algorithm for edit distance between text trees\n",
    "\n",
    "This notebook contains the implementation of a simple yet informative metric for text tree comparison. This way of text tree similarity measurement can be used, for example, to compare salient sentence-based mind maps generated by a neural network with reference maps. The way this algorithm works is by applying the Zhang-Shasha algorithm for tree edit distance to text trees, using semantic similarity as the cost of node updates. To measure semantic similarity of sentences in tree nodes, we use a BERT-like language model's embeddings of the sentences, given the context of all parent nodes if available, and compare these embeddings directly.\n",
    "\n",
    "The Zhang-Shasha algorithm implementation is taken from the `zss` Python library developed by Tim Henderson and Steve Johnson (2013). _[here goes the description of what model we use and how we compare embeddings from it]_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4243aa5-af88-4611-b528-5f891595f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zss\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be46c9-c8f8-44c1-b54e-af6f50e02725",
   "metadata": {},
   "source": [
    "First, we will slightly extend the `Node` class from `zss` to include depth information in tree nodes. This will later be useful for similarity weight adjustment for nodes of different depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9861b3b5-885b-49e7-a8fe-6bcedf9c90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(zss.Node):\n",
    "    def __init__(self, label, children=None, depth=0):\n",
    "        '''\n",
    "        Updated version of Node constructor containing self.depth initialization.\n",
    "        '''\n",
    "        self.label = label\n",
    "        self.children = children or list()\n",
    "        self.depth = depth\n",
    "\n",
    "    @staticmethod\n",
    "    def get_depth(node):\n",
    "        '''\n",
    "        Method that returns the node's depth field.\n",
    "        '''\n",
    "        return node.depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c601e95-79d3-49fc-8ce6-a66e195bed32",
   "metadata": {},
   "source": [
    "Also we will need a function to relabel text trees so that each node contains all of the parent nodes' labels a context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fddfc61-69ef-46c9-9614-bf8cac3dc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_with_context(input_node: Node):\n",
    "    '''\n",
    "    A function that creates a relabeled tree based on the input one by adding sentences from parent nodes as context to child nodes.\n",
    "\n",
    "    Arguments:\n",
    "    input_node - root node of the tree to be relabeled.\n",
    "\n",
    "    Output: \n",
    "    Root node of relabeled tree.\n",
    "    '''\n",
    "    def add_context(node: Node, context):\n",
    "        new_node = Node(context + Node.get_label(node), depth=Node.get_depth(node))\n",
    "        \n",
    "        for child_node in Node.get_children(node):\n",
    "            new_node.addkid(add_context(child_node, Node.get_label(new_node)))\n",
    "        \n",
    "        return new_node\n",
    "\n",
    "    return add_context(input_node, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52233b02-01b9-4a79-8cf1-dedc9022c523",
   "metadata": {},
   "source": [
    "To speed the algorithm up, we will implement semantic distance precomputation for Zhang-Shasha's algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "403d3bae-81e1-434c-8649-74f814f58f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(tree: Node):\n",
    "    '''\n",
    "    A utility function that uses DFS to traverse a tree and extract all of its sentences.\n",
    "\n",
    "    Arguments:\n",
    "    tree - a text tree of the type Node.\n",
    "\n",
    "    Output:\n",
    "    sentences: list(string) - a list of all the sentences in tree.\n",
    "    '''\n",
    "    sentences = [Node.get_label(tree)]\n",
    "    for child in Node.get_children(tree):\n",
    "        sentences += extract_sentences(child)\n",
    "\n",
    "    return sentences\n",
    "    \n",
    "\n",
    "def precompute_dists(tree_a: Node, tree_b: Node, encoder, embedding_dist):\n",
    "    '''\n",
    "    A helper function to precompute semantic distance between pairs of sentences in two text trees.\n",
    "\n",
    "    Arguments:\n",
    "    tree_a, tree_b - two trees of the zss type Node;\n",
    "    similarity_func - a function of two string arguments which computes sentence distance.\n",
    "    encoder - a language model's callable encoder that takes string input returns embeddings from the model\n",
    "    embedding_dist - an embedding similarity measure that takes two embeddings as input and returns a non-negative distance value. \n",
    "\n",
    "    Output:\n",
    "    sentence_dists: dict(dict(string: float)) - a 2-D dict containing scores for each pair of sentences from tree_a and tree_b.\n",
    "    sentence_weights: dict(string: float) - a dict containing sentence weights (that is, distances to \"\") for deletion and insertion operation costs\n",
    "    '''\n",
    "    sentences_a, sentences_b = extract_sentences(tree_a), extract_sentences(tree_b)\n",
    "    embeddings_a, embeddings_b = encoder(sentences_a), encoder(sentences_b)\n",
    "\n",
    "    sentence_dists = {}\n",
    "    for sentence in sentences_a:\n",
    "        sentence_dists[sentence] = {}\n",
    "\n",
    "    for sent_a, emb_a in zip(sentences_a, embeddings_a):\n",
    "        for sent_b, emb_b in zip(sentences_b, embeddings_b):\n",
    "            sentence_dists[sent_a][sent_b] = embedding_dist(emb_a, emb_b)\n",
    "\n",
    "    sentence_weights = {}\n",
    "    empty_emb = encoder(\"\")\n",
    "    for sent, emb in zip(sentences_a + sentences_b, embeddings_a + embeddings_b):\n",
    "        sentence_weights[sent] = embedding_dist(emb, empty_emb)\n",
    "\n",
    "    return sentence_dists, sentence_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73cc59e-1796-4836-a2a4-8ef96f329c21",
   "metadata": {},
   "source": [
    "Finally, we use all the functions above to compute tree distance with `zss.distance`. Note the possible usage of a depth factor to adjust update costs according to the updated node's depth. Our approach can be modified to factor in node depth in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29107705-2429-4aba-b5ff-5299be4b1e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tree_distance(tree_a: Node, tree_b: Node, encoder, embedding_dist, depth_factor=1.0, use_context=True):\n",
    "    '''\n",
    "    The function that calculates tree edit distance between to trees given a similarity function for sentence pairs.\n",
    "    \n",
    "    Arguments:\n",
    "    tree_a, tree_b - two trees of the zss type Node to be compared;\n",
    "    similarity_func - a function of two string arguments which computes sentence distance;\n",
    "    depth_factor - a hyperparameter that scales sentence similarity based on the node's depth;\n",
    "    use_context - a flag indicating whether parents of the given node will be used as context for sentence comparison.\n",
    "\n",
    "    Output:\n",
    "    dist: float - the calculated tree edit distance between tree_a and tree_b\n",
    "    '''\n",
    "    if use_context:\n",
    "        tree_a = tree_with_context(tree_a)\n",
    "        tree_b = tree_with_context(tree_b)\n",
    "\n",
    "    ###################################### TOOOOOOOOO-DOOOOOOOOOOOOOO ####################################\n",
    "    def similarity_func(sentence_a, sentence_b):\n",
    "        a_embedding = encoder(sentence_a)\n",
    "        b_embedding = encoder(sentence_b)\n",
    "\n",
    "        return embedding_dist(a_embedding, b_embedding)\n",
    "\n",
    "    # Here we define the update_cost, insert_cost and delete_cost functions needed for Zhang-Shasha's algorithm using the provided similarity function.\n",
    "    def update_cost(node_a: Node, node_b: Node):\n",
    "        return similarity_func(Node.get_label(node_a), Node.get_label(node_b)) * depth_factor**Node.get_depth(node_a)\n",
    "\n",
    "    def insert_cost(node: Node):\n",
    "        # We define node insertion and deletion costs as similarity of the node's label to an empty string\n",
    "        return similarity_func(Node.get_label(node), \"\")\n",
    "\n",
    "    def remove_cost(node: Node):\n",
    "        return similarity_func(Node.get_label(node), \"\")\n",
    "\n",
    "    dist = zss.distance(tree_a, tree_b, Node.get_children, insert_cost, remove_cost, update_cost)\n",
    "    return dist\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b185e2b-47f6-458e-aa66-2b068b093e17",
   "metadata": {},
   "source": [
    "We will also include a version of the `text_tree_distance` function without precomputation to assess the increase in performance that precomputation allows to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b69e0de0-b7b5-4ee0-8c48-fb0ec752e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tree_distance_w_o_precomputation(tree_a: Node, tree_b: Node, encoder, embedding_dist, depth_factor=1.0, use_context=True):\n",
    "    '''\n",
    "    A modified version of text_tree_distance that doesn't incorporate precomputation.\n",
    "    It calculates tree edit distance between to trees given a similarity function for sentence pairs.\n",
    "    \n",
    "    Arguments:\n",
    "    tree_a, tree_b - two trees of the zss type Node to be compared;\n",
    "    similarity_func - a function of two string arguments which computes sentence distance;\n",
    "    depth_factor - a hyperparameter that scales sentence similarity based on the node's depth;\n",
    "    use_context - a flag indicating whether parents of the given node will be used as context for sentence comparison.\n",
    "\n",
    "    Output:\n",
    "    dist: float - the calculated tree edit distance between tree_a and tree_b\n",
    "    '''\n",
    "    if use_context:\n",
    "        tree_a = tree_with_context(tree_a)\n",
    "        tree_b = tree_with_context(tree_b)\n",
    "\n",
    "    def similarity_func(sentence_a, sentence_b):\n",
    "        a_embedding = encoder(sentence_a)\n",
    "        b_embedding = encoder(sentence_b)\n",
    "\n",
    "        return embedding_dist(a_embedding, b_embedding)\n",
    "\n",
    "    # Here we define the update_cost, insert_cost and delete_cost functions needed for Zhang-Shasha's algorithm using the provided similarity function.\n",
    "    def update_cost(node_a: Node, node_b: Node):\n",
    "        return similarity_func(Node.get_label(node_a), Node.get_label(node_b)) * depth_factor**Node.get_depth(node_a)\n",
    "\n",
    "    def insert_cost(node: Node):\n",
    "        # We define node insertion and deletion costs as similarity of the node's label to an empty string\n",
    "        return similarity_func(Node.get_label(node), \"\")\n",
    "\n",
    "    def remove_cost(node: Node):\n",
    "        return similarity_func(Node.get_label(node), \"\")\n",
    "\n",
    "    dist = zss.distance(tree_a, tree_b, Node.get_children, insert_cost, remove_cost, update_cost)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57bcaf9-f6e8-4cbd-b58a-b017cda31fe4",
   "metadata": {},
   "source": [
    "Below we provide an example use case of the functions above utilizing a model from `sentence_transformers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "381a7a28-d3a0-486b-a150-960b6cc7c545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8631a1fdb0d34844bb918c08408bb165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe3e56dacc549c890fb1d26b0bd1f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a0acdcebd947dba0e307ce450ae344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde96a4845284d39a79e8dfb8e5136bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca5ec0bd18d4a8ebe8e5e4b18870df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/556 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cad070a860f41c28aa6c28cf42694c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edccb4d97b64e24b7cff126e5cdcb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/452 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb119b218b44815acbc3437ac62660a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3e8fc771694b9399940ae1842df217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea377ce1d9f4eefb34d9c5103edeba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409000713589461a9506cea4c049537c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0a2f197f71421e8b391e3d84ec195c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c2095c1f38411abf8b439cfcad56f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1200520493496982c056d4e52e958c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v1')\n",
    "\n",
    "def cos_dist(a_embedding, b_embedding):\n",
    "    return float(1 - model.similarity(a_embedding, b_embedding))\n",
    "\n",
    "similarity_func = sentence_similarity(model.encode, cos_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb018879-8685-4c82-9ecb-fb9fb3869dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = (\n",
    "    Node('We present a new metric for text tree comparison.', depth=0)\n",
    "        .addkid(Node('It uses Zhang-Shasha\\'s algorithm and a BERT-like model.', depth=1)\n",
    "            .addkid(Node('Zhang-Shasha\\'s algorithm is used to measure tree edit distance effectively.', depth=2))\n",
    "            .addkid(Node('The BERT-like model is used to measure semantic similarity.', depth=2)))\n",
    "        .addkid(Node('The algorithm is presented as an informative metric for text tree comparison.', depth=1)\n",
    "            .addkid(Node('There hasn\\'t yet been a metric that allows to compare tree-structured text data such as mind maps informatively.', depth=2))\n",
    "            .addkid(Node('This metric can be used, for example, to evaluate automatic salient sentence-based mind map generation.', depth=2)))\n",
    ")\n",
    "\n",
    "B = (\n",
    "    Node('A new metric for text tree comparison based on tree edit distance and semantic similarity.', depth=0)\n",
    "        .addkid(Node('Zhang-Shasha\\'s algorithm is used to compute tree edit distance.', depth=1))\n",
    "        .addkid(Node('Semantic similarity is measured using a BERT-like language model.', depth=1)\n",
    "            .addkid(Node('To measure it, the sentences with all parent nodes as context are passed to the language model.', depth=2))\n",
    "            .addkid(Node('Semantic similarity is measured as the similarity of the model\\'s embeddings of the sentences.', depth=2)))\n",
    "        .addkid(Node('This metric can be used to compare text trees.', depth=1)\n",
    "            .addkid(Node('For example, it can be utilized in automatic mind map generation evaluation against reference maps.', depth=2)))\n",
    ")\n",
    "\n",
    "C = (\n",
    "    Node('A new algorithm for text tree edit distance based on Zhang-Shasha\\'s algorithm and BERT-like model embedding similarity.', depth=0)\n",
    "        .addkid(Node('The algorithm\\'s novelty is in its similarity measure based on BERT-like model embeddings.', depth=1)\n",
    "            .addkid(Node('Embedding distance is used as a measure of semantic similarity.', depth=2))\n",
    "            .addkid(Node('The language model allows to capture semantic meaning of sentences and model their similarity.', depth=2)))\n",
    "        .addkid(Node('Zhang-Shasha\\'s algorithm is used to compute tree edit distance with new edit costs.', depth=1)\n",
    "            .addkid(Node('Semantic similarity is used as the update cost in the algorithm.', depth=2))\n",
    "            .addkid(Node('The costs of insertion and removal of nodes are defined as the similarity of the node and an empty sentence.', depth=2)))\n",
    "        .addkid(Node('The proposed algorithm is presented as a more informative metric of similarity between text trees', depth=1)\n",
    "            .addkid(Node('The current ways of comparing text trees overlook overlook their tree structure or the meaning of their labels.', depth=2))\n",
    "            .addkid(Node('This new method can be used, for example, to compare mind maps or hierarchical summaries.', depth=2)))\n",
    ")\n",
    "\n",
    "A_B_dist = text_tree_distance(A, B, similarity_func)\n",
    "A_C_dist = text_tree_distance(A, C, similarity_func)\n",
    "C_B_dist = text_tree_distance(C, B, similarity_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18b9c890-2132-4358-bf24-75a32c1cec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2734222412109375\n",
      "4.964913785457611\n",
      "5.261121928691864\n"
     ]
    }
   ],
   "source": [
    "print(A_B_dist)\n",
    "print(A_C_dist)\n",
    "print(C_B_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7a58a8e-c76d-4a26-aa2b-be5f75688999",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_B_dist_0_7 = text_tree_distance(A, B, similarity_func, depth_factor=0.7)\n",
    "A_B_dist_1_5 = text_tree_distance(A, B, similarity_func, depth_factor=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79a7fa99-39b9-4aad-8396-1ed542a7fb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.860270586013794\n",
      "4.1851606369018555\n"
     ]
    }
   ],
   "source": [
    "print(A_B_dist_0_7)\n",
    "print(A_B_dist_1_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
