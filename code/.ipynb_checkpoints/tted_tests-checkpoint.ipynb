{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc7dad8-f70a-4e2f-9632-5bfeed842777",
   "metadata": {},
   "source": [
    "# Text tree edit distance: a language model-based metric for text hierarchy comparison.\n",
    "\n",
    "This notebook contains the implementation of a simple yet informative metric for text tree comparison. This way of text tree similarity measurement can be used, for example, to compare sentence-based mind maps generated by a neural network with reference maps to assess generation quality. The way this algorithm works is by using the Zhang-Shasha algorithm to compute tree edit distance with semantic distance between the sentences in the nodes as the cost of node updates. To measure semantic distance between sentences, we compute the distance between the sentences' embeddings produced by an encoder language model.\n",
    "\n",
    "The Zhang-Shasha algorithm implementation used here is from the `edist` Python library developed by Benjamin Paassen (2019-2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530439a-0f83-4f55-b8f4-06a96d02fbd2",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4243aa5-af88-4611-b528-5f891595f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
    "\n",
    "from tted.tree_format import TextTree\n",
    "from tted.computation import tted, avg_tted\n",
    "from tted.baseline import baseline_distance, baseline_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfc28a0-cf33-4535-a064-e35b85e783d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot formatting\n",
    "plt.rcParams['font.family'] = 'DejaVu Serif'\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['lines.markersize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 24\n",
    "plt.rcParams['ytick.labelsize'] = 24\n",
    "plt.rcParams['legend.fontsize'] = 24\n",
    "plt.rcParams['axes.titlesize'] = 36\n",
    "plt.rcParams['axes.labelsize'] = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285ec1f-60ec-49c1-9b14-212967db34bd",
   "metadata": {},
   "source": [
    "We will use text trees stored in the JSON format as in the following example:\n",
    "```json\n",
    "{\n",
    "  \"A new algorithm for text tree edit distance based on Zhang-Shasha's algorithm and BERT-like model embedding similarity.\": {\n",
    "    \"The algorithm's novelty is in its similarity measure based on BERT-like model embeddings.\": {\n",
    "      \"Embedding distance is used as a measure of semantic similarity.\": {},\n",
    "      \"The language model allows to capture semantic meaning of sentences and model their similarity.\": {}\n",
    "    },\n",
    "    \"Zhang-Shasha's algorithm is used to compute tree edit distance with new edit costs.\": {\n",
    "      \"Semantic similarity is used as the update cost in the algorithm.\": {},\n",
    "      \"The costs of insertion and removal of nodes are defined as the similarity of the node and an empty sentence.\": {}\n",
    "    },\n",
    "    \"The proposed algorithm is presented as a more informative metric of similarity between text trees.\": {\n",
    "      \"The current ways of comparing text trees overlook their tree structure or the meaning of their labels.\": {},\n",
    "      \"This new method can be used, for example, to compare mind maps or hierarchical summaries.\": {}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "We use the similarity function from \"Coherence Graph Guidance for Mind-Map Generation\" (Zhang et al., 2024) and a pseudometric based on it as a baseline for comparison. The full original code from this paper can be found at https://github.com/Cyno2232/CMGN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad8b85-5092-4585-a1d2-08451aae951b",
   "metadata": {},
   "source": [
    "## Basic tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57bcaf9-f6e8-4cbd-b58a-b017cda31fe4",
   "metadata": {},
   "source": [
    "Below we provide an example use case of the functions above utilizing a model from `sentence_transformers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb018879-8685-4c82-9ecb-fb9fb3869dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = TextTree([\n",
    "    'We present a new metric for text tree comparison.', \n",
    "    'It uses Zhang-Shasha\\'s algorithm and a BERT-like model.', \n",
    "    'Zhang-Shasha\\'s algorithm is used to measure tree edit distance effectively.', \n",
    "    'The BERT-like model is used to measure semantic similarity.', \n",
    "    'The algorithm is presented as an informative metric for text tree comparison.', \n",
    "    'There hasn\\'t yet been a metric that allows to compare tree-structured text data such as mind maps informatively.', \n",
    "    'This metric can be used, for example, to evaluate automatic salient sentence-based mind map generation.'\n",
    "],\n",
    "[[1, 4], [2, 3], [], [], [5, 6], [], []])\n",
    "\n",
    "B = TextTree([\n",
    "    'A new metric for text tree comparison based on tree edit distance and semantic similarity.',\n",
    "    'Zhang-Shasha\\'s algorithm is used to compute tree edit distance.', \n",
    "    'Semantic similarity is measured using a BERT-like language model.', \n",
    "    'To measure it, the sentences with all parent nodes as context are passed to the language model.', \n",
    "    'Semantic similarity is measured as the similarity of the model\\'s embeddings of the sentences.', \n",
    "    'This metric can be used to compare text trees.', \n",
    "    'For example, it can be utilized in automatic mind map generation evaluation against reference maps.'\n",
    "],\n",
    "[[1, 2, 5], [], [3, 4], [], [], [6], []])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f830f96-2097-4453-be3d-124c3600115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/paraphrase-distilroberta-base-v2')\n",
    "def cos_dist(a_embedding, b_embedding):\n",
    "        return np.sqrt(1 - model.similarity(a_embedding, b_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5f3488-843d-4772-a73b-6637fdb042af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35875844837353066\n",
      "0.5293097216099977\n",
      "0.5674165042314459\n",
      "CPU times: total: 2.33 s\n",
      "Wall time: 306 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(1, 4):\n",
    "    AB_dist = tted(A, B, model.encode, cos_dist, normalize=True, unordered=False, use_context=False, at=i)\n",
    "    print(AB_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4ba9aa-adc1-44c6-847c-bd2d7a4bfc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4851615580716581\n",
      "CPU times: total: 2 s\n",
      "Wall time: 250 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "avg_AB_dist = avg_tted(A, B, model.encode, cos_dist, unordered=False, use_context=False)\n",
    "print(avg_AB_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d6e96c-1e00-4bd8-a340-cf312299b34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9569458062757326\n",
      "CPU times: total: 1.5 s\n",
      "Wall time: 186 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "AB_base_dist = baseline_distance(A, B)\n",
    "print(AB_base_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6163d31b-5e56-4cd2-876d-232b26c1bb28",
   "metadata": {},
   "source": [
    "## Main experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad248f-b863-4b85-8985-3bf94d925a3f",
   "metadata": {},
   "source": [
    "Now we can run a couple of experiments to evaluate these two metrics on simple test cases. We'll compare the methods on three text tree sets, each containing different modifications of a base tree:\n",
    "1) A set of trees that are identical in semantic meaning and structure, but the sentences in the tree nodes are paraphrased;\n",
    "2) A set of trees that are formed from the same sentences, but in different tree order;\n",
    "3) A set of trees that have identical structure but are significantly different in meaning.\n",
    "\n",
    "For each set of trees we'll compute pairwise similarity scores with my metric and the baseline method. The goal is to capture the difference in meaning and structure of the trees while minimizing the distance between trees that are, in a sense, paraphrases of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3eafc5-6c87-4a70-8a73-ed74a20d3327",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1d72028-5b5b-4170-8740-ae0bd802d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(method, model=None, dist=None, unordered=True, use_context=False, filename=None):\n",
    "    scores = {}\n",
    "    times = {}\n",
    "    \n",
    "    test_cases = ['paraphrase', 'meaning', 'structure']\n",
    "    sizes = [5, 10, 15, 20, 25]\n",
    "    set_count = 5\n",
    "    sample_count = 5\n",
    "\n",
    "    for size in tqdm(sizes, leave=False):\n",
    "        scores[size] = {}\n",
    "        for test_case in test_cases:\n",
    "            scores[size][test_case] = []\n",
    "        for k in tqdm(range(set_count), leave=False):\n",
    "            base_tree = TextTree.from_json(f'data/tted_test/size_{size}/set_{k}/base_tree.json')\n",
    "            total_time = 0\n",
    "            for test_case in test_cases:\n",
    "                path = f'data/tted_test/size_{size}/set_{k}/{test_case}_'\n",
    "        \n",
    "                trees = []\n",
    "                for i in range(sample_count):\n",
    "                    trees.append(TextTree.from_json(path + str(i) + '.json'))\n",
    "        \n",
    "                start_time = time.time()\n",
    "                for i in range(sample_count):\n",
    "                    if method == 'tted':\n",
    "                        new_dist = avg_tted(\n",
    "                            base_tree, trees[i], \n",
    "                            encoder=model, \n",
    "                            embedding_dist=dist, \n",
    "                            unordered=unordered, \n",
    "                            use_context=use_context\n",
    "                        )\n",
    "                    elif method == 'baseline':\n",
    "                        new_dist = baseline_distance(base_tree, trees[i])\n",
    "                    elif method == 'baseline_sim':\n",
    "                        new_dist = baseline_similarity(base_tree, trees[i])\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                    if not np.isnan(new_dist):\n",
    "                        scores[size][test_case].append(new_dist)\n",
    "        \n",
    "                total_time += time.time() - start_time\n",
    "\n",
    "        times[size] = total_time / (set_count * sample_count * len(test_cases))\n",
    "\n",
    "    if filename:\n",
    "        data_path = 'data/results/'\n",
    "        with open(data_path+filename, 'w') as f:\n",
    "            json.dump(scores, f, indent=4)\n",
    "    \n",
    "    return scores, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb0710e-ceb5-4f96-a637-79597c0c012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_scores(scores, plot_title, filename):\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "    ax.boxplot(scores.values(), vert=False)\n",
    "\n",
    "    ax.set_xlabel(r'$\\rho(T, \\cdot)$')\n",
    "    ax.set_xlim(0)\n",
    "    ax.set_yticklabels(scores.keys())\n",
    "    ax.grid()\n",
    "    if plot_title is not None:\n",
    "        ax.set_title(plot_title)\n",
    "\n",
    "    fig.savefig('../img/' + filename, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc335485-630e-4a4d-806e-45311170a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores, plot_title, filename):\n",
    "    exps = ('paraphrase', 'structure', 'meaning')\n",
    "    size_range = np.arange(5, 26, 5)\n",
    "\n",
    "    markers = ['x', 'o', '*']\n",
    "    for exp, marker in zip(exps, markers):\n",
    "        means = np.array([np.mean(scores[n][exp]) for n in size_range])\n",
    "        stds = np.array([np.std(scores[n][exp]) for n in size_range])\n",
    "        plt.plot(size_range, means, label=exp, marker=marker)\n",
    "        plt.fill_between(size_range, means - stds, means + stds, alpha=0.25)\n",
    "    \n",
    "    plt.xlabel(r'Tree size, $|T|$')\n",
    "    plt.ylabel(r'Mean distance, $\\overline{\\rho}$') # For distance\n",
    "    # plt.ylabel(r'Mean similarity, $\\overline{\\text{Sim}}$') # For similarity\n",
    "    plt.ylim(0)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(\"../img/\"+filename, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84656d1a-b3e7-4559-a0c2-04e125cfa1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_frame(scores, method_name):\n",
    "    results_array = [method_name]\n",
    "    \n",
    "    for exp in ('paraphrase', 'structure', 'meaning'):\n",
    "        results_array.append(np.mean(scores[10][exp]))\n",
    "        results_array.append(np.std(scores[10][exp]))\n",
    "    for exp in ('structure', 'meaning'):\n",
    "        quality_coeffs = []\n",
    "        for size in scores.keys():\n",
    "            quality_coeffs.extend([a / b for a in scores[size]['paraphrase'] for b in scores[size][exp]])\n",
    "        results_array.append(np.mean(quality_coeffs))\n",
    "        results_array.append(np.std(quality_coeffs))\n",
    "\n",
    "    results_array = [results_array]\n",
    "    frame = pd.DataFrame(results_array, columns=['Method', \n",
    "                                                 'Paraphrase mean', \n",
    "                                                 'Paraphrase std', \n",
    "                                                 'Restructure mean',\n",
    "                                                 'Restructure std',\n",
    "                                                 'Meaning mean', \n",
    "                                                 'Meaning std', \n",
    "                                                 'R_S score',\n",
    "                                                 'R_S std',\n",
    "                                                 'R_M score',\n",
    "                                                 'R_M std'])\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ff3c8d-9bd7-4f7c-a26d-52d0132d830a",
   "metadata": {},
   "source": [
    "### Experiment runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e94c846-cb6f-4ded-8a76-b8363258bd64",
   "metadata": {},
   "source": [
    "Below are our experiments with several language models and distance metrics, with and without context usage, in comparison to the baseline method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "601a5972-a09c-4ba0-9a08-247e3a46f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {}\n",
    "times_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdbb162c-93ee-4fea-b8a9-b901087a03e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156c1cf42f474cfdbe23ba7ffe9a75e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05c6ce1b0a3491c8d2ec81c6eb13433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95ea12aaab94cbabab6768355962899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5933085995744474ac478b90d43227dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d50c4208524cd7b89cfeaee4b02112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15663ffb45564c49aa9008e97f9f78cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict['baseline'], _ = run_test('baseline', filename='baseline.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57c64581-c41a-4491-ae3b-688eab65eab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ec9499d7d746b59847bac2f4aedf43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c34af4b0701464dbc88f9ad3d0700dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af60d6871cd4064828434f630936ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e451d9dcdf324854bc2df8d8a4de16bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16571097fc0e42c4bb879ec6093ff6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a939cc581d4bb0b4bf79366dbcda37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_sims, times_dict['baseline'] = run_test('baseline_sim', filename='baseline_sim.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6a9c82e-6b14-437a-b00e-4edc436da38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['sentence-transformers/paraphrase-distilroberta-base-v2',\n",
    "              'sentence-transformers/allenai-specter',\n",
    "              'sentence-transformers/all-mpnet-base-v2',\n",
    "              'sentence-transformers/paraphrase-multilingual-mpnet-base-v2']\n",
    "model_labels = ['distilroberta',\n",
    "                'specter',\n",
    "                'mpnet',\n",
    "                'tuned_mpnet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907504b-e2e6-45ee-b5a1-67b069eb1259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7b335d98a842a5aa471d7fda5ef358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c38df3514446e5a1857cdbfecbc5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed268c29e24c4eca9e5ec845cd4971a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492305ec86fb46abadbcd112712f9eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813e21643a3c4f90944040881a090e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4aeddd19ab49388e6f9b3cfd3efa67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f821ca6ac2e649f58634776272d6ee95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e494e98cd6364389bfe2a6b9c71a9cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc4cb15a9ac4aa18b4a03ea7cc11946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cb5874520741448621a04f296479d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15f339d215f49dba5aafa6b87ac4fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a04e175b8046a9b6a50c52e30251d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065b832cf71446d5a97ae344b8f9f1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb776a79e2db49c8af5d7871ccaf0c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d661522a99ae43458566d1403e3c53ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190a83968f66423a8816b83d68cd5f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de44f7f314044e6aaa92788bb45f7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8601354bb15c45d3a7a523f4148a1a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd31ce870e19457c850b9b9059713a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7cca8cc5d34aecb23ac15a745dac13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10c2dbde99c45e2a47569244f939e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d768480b4344c3acce367f9cb1a22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c5a9c44fb04c418bfa68fe63e9ee38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf6ddfb160c42f398fcf45f5aa60354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_name, model_label in zip(model_names, model_labels):\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # The default similarity function for all of the models above is the cosine similarity function\n",
    "    def dist(a_embedding, b_embedding):\n",
    "        return float(np.sqrt(1 - model.similarity(a_embedding, b_embedding)))\n",
    "\n",
    "    scores_dict[model_name], times_dict[model_name] = run_test('tted', model=model.encode, dist=dist, filename=model_label+'.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a7fb38-0d57-42a5-97fd-1f8390c3a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different distance measures\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "for sim_measure, measure_name in zip([SimilarityFunction.EUCLIDEAN, SimilarityFunction.MANHATTAN], ['euclidian', 'manhattan']):\n",
    "    model.similarity_fn_name = sim_measure\n",
    "    def dist(embedding_a, embedding_b):\n",
    "        return float(-model.similarity(embedding_a, embedding_b))\n",
    "        \n",
    "    scores_dict[measure_name], times_dict[measure_name] = run_test('tted', model=model.encode, dist=dist, filename=measure_name+'.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970127a9-6057-47ba-aebd-a1910f0c35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with context usage\n",
    "model.similarity_fn_name = SimilarityFunction.COSINE\n",
    "def dist(a_embedding, b_embedding):\n",
    "    return float(np.sqrt(1 - model.similarity(a_embedding, b_embedding)))\n",
    "\n",
    "scores_dict['With context'], times_dict['With context'] = run_test('tted', model=model.encode, dist=dist, use_context=True, filename='context.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbeaff3-d2c5-4a2e-b99e-21b19799f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in scores_dict.keys():\n",
    "    for size in scores_dict[exp].keys():\n",
    "        for case in scores_dict[exp][size].keys():\n",
    "            npar = np.array(scores_dict[exp][size][case])\n",
    "            scores_dict[exp][size][case] = npar[npar != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbb16f9-5d95-4d6d-9b08-4f761d76895d",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e616b-5b0e-469a-98be-31bae7d4d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dict = {}\n",
    "method_names = ['Baseline method',\n",
    "                'TTED with fine-tuned DistilRoBERTa',\n",
    "                'TTED with SPECTER',\n",
    "                'TTED with untuned MPNet',\n",
    "                'TTED with fine-tuned MPNet',\n",
    "                'TTED with MPNet and Euclidian distance',\n",
    "                'TTED with MPNet and Manhattan distance',\n",
    "                'TTED with MPNet and context']\n",
    "\n",
    "for exp_name, method_name in zip(scores_dict.keys(), method_names):\n",
    "    frames_dict[exp_name] = result_frame(scores_dict[exp_name], method_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989aceb-6fce-4adf-b9e7-cb7db269a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frame = pd.concat(frames_dict.values())\n",
    "final_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d20e88-97c1-448b-96d1-26ee6ccb6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_scores(scores_dict['sentence-transformers/all-mpnet-base-v2'][15], \n",
    "            '',\n",
    "            'mpnet_box.png')\n",
    "boxplot_scores(scores_dict['baseline'][15], '', 'baseline_box.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59499d-62fd-44c5-9f8a-4db80ad95e05",
   "metadata": {},
   "source": [
    "### Distance scores for different tree sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b875b-0fd5-4ad0-89bf-9820f393fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(baseline_sims, '', 'baseline_sim_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457f333-0633-45a3-b89f-dcc1faea60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(scores_dict['baseline'], '', 'baseline_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5f2e02-bf3c-454d-8da5-e7e1fa7cc2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(scores_dict['sentence-transformers/paraphrase-multilingual-mpnet-base-v2'], '', 'tuned_mpnet_graph_avg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f7952-bb14-4f19-85c2-ad459acb9dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(scores_dict['sentence-transformers/all-mpnet-base-v2'], '', 'mpnet_graph_avg.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481812f-f73e-4ea5-9b6a-3ad4a6069de8",
   "metadata": {},
   "source": [
    "## Computation time measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d458f05-3e8a-4c67-999a-8b7e8eb0a5b3",
   "metadata": {},
   "source": [
    "Here, we measure the time that it takes to compute TTED and the baseline similarity score for full binary text trees of depths 2 to 6 to see how the two methods scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ecdbb6-cf02-496b-abf2-ef9516ee1153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth = 9\n",
    "# n_range = np.arange(2, max_depth+1)\n",
    "# sample_count = 5\n",
    "\n",
    "# def measure_time(func):\n",
    "#     times = {}\n",
    "#     for n in tqdm(n_range):\n",
    "#         times[n] = []\n",
    "#         trees = []\n",
    "#         for i in range(sample_count):\n",
    "#             trees.append(TextTree.from_json(f'data/tted_time_test/depth_{n}/map_{i}.json'))\n",
    "                                      \n",
    "#         for i in range(sample_count - 1):\n",
    "#             for j in range(i+1, sample_count):\n",
    "#                 start_time = time.time()\n",
    "#                 func(trees[i], trees[j])\n",
    "#                 times[n].append(time.time() - start_time)\n",
    "                \n",
    "#     return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e6393-7f78-4684-a400-854b6303c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_times = measure_time(baseline_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a563ec-2c43-483d-8056-f4c67fb04049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measured_times = []\n",
    "\n",
    "# def cos_dist(a_embedding, b_embedding):\n",
    "#         return float(1 - model.similarity(a_embedding, b_embedding))\n",
    "\n",
    "# for i in range(len(model_names)):\n",
    "#     model = SentenceTransformer(model_names[i])\n",
    "#     func = lambda a, b: tted(a, b, model.encode, cos_dist, False)\n",
    "#     measured_times.append(measure_time(func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aae3ae-caa1-448d-8bb0-8b24d52ebb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_labels = [\n",
    "#     'TTED with paraphrase DistilRoBERTa',\n",
    "#     'TTED with SPECTER',\n",
    "#     'TTED with untuned MPNet',\n",
    "#     'TTED with paraphrase MPNet'\n",
    "# ]\n",
    "# plt.rcParams['legend.fontsize'] = 12\n",
    "\n",
    "# for i in range(len(model_names)):\n",
    "#     means = np.array([np.mean(measurement) for measurement in measured_times[i].values()])\n",
    "#     stds = np.array([np.std(measurement) for measurement in measured_times[i].values()])\n",
    "#     plt.plot(n_range, means, label=model_labels[i])\n",
    "#     plt.fill_between(n_range, means - stds, means + stds, alpha=0.25)\n",
    "\n",
    "# means = np.array([np.mean(measurement) for measurement in baseline_times.values()])\n",
    "# stds = np.array([np.std(measurement) for measurement in baseline_times.values()])\n",
    "# plt.plot(n_range, means, linestyle='--', label=\"Baseline\")\n",
    "# plt.fill_between(n_range, means - stds, means + stds, alpha=0.25)\n",
    "\n",
    "# plt.xlabel(r'$d$')\n",
    "# plt.ylabel(r'$t$, Ñ')\n",
    "# plt.yscale('log')\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "\n",
    "# plt.savefig(\"../img/computation_times.png\", bbox_inches='tight', pad_inches=0.1)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
